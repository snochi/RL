\BOOKMARK [1][-]{section.1}{Introduction\040to\040Reinforcement\040Learning}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Introduction}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{The\040RL\040Problem}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Inside\040an\040RL\040Agent}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Problems\040within\040RL}{section.1}% 5
\BOOKMARK [1][-]{section.2}{Markov\040Decision\040Processes}{}% 6
\BOOKMARK [2][-]{subsection.2.1}{Markov\040Processes}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.2}{Markov\040Decision\040Processes}{section.2}% 8
\BOOKMARK [1][-]{section.3}{Planning\040by\040Dynamic\040Programming}{}% 9
\BOOKMARK [2][-]{subsection.3.1}{Introduction}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.2}{Policy\040Evaluation}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.3}{Policy\040Iteration}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.4}{Value\040Iteration}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.5}{Summary}{section.3}% 14
\BOOKMARK [2][-]{subsection.3.6}{Extensions\040to\040Dynamic\040Programming}{section.3}% 15
